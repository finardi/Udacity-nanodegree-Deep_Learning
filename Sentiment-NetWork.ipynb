{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:30.861777",
     "start_time": "2017-04-21T10:44:30.764461"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import time \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:30.987207",
     "start_time": "2017-04-21T10:44:30.865606"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open file reviews\n",
    "with open('reviews.txt', 'r', encoding='utf-8') as rev:\n",
    "    reviews = list(map(lambda x: x[:-1], rev.readlines()))\n",
    "rev.close()\n",
    "\n",
    "# open file labels\n",
    "with open('labels.txt', 'r', encoding='utf-8') as lab:\n",
    "    labels = list(map(lambda x: x[:-1], lab.readlines()))\n",
    "lab.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:30.994340",
     "start_time": "2017-04-21T10:44:30.988832"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(reviews) 25000\n",
      "\n",
      "len(labels) 25000\n"
     ]
    }
   ],
   "source": [
    "print('len(reviews)',len(reviews))\n",
    "print('\\nlen(labels)',len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:31.081823",
     "start_time": "2017-04-21T10:44:30.996913"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews[0]= bromwell high is a cartoon comedy . it ran at the same time as some other progra\n",
      "\n",
      "labels[0]= positive\n"
     ]
    }
   ],
   "source": [
    "print('reviews[0]=', reviews[0][:80])\n",
    "\n",
    "print('\\nlabels[0]=', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:31.170085",
     "start_time": "2017-04-21T10:44:31.084134"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:40.663341",
     "start_time": "2017-04-21T10:44:31.171927"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range(len(reviews)):\n",
    "    if(labels[_]=='positive'):\n",
    "        for word in reviews[_].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word]    += 1\n",
    "    else:\n",
    "        for word in reviews[_].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word]    += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:40.668833",
     "start_time": "2017-04-21T10:44:40.665278"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:40.933529",
     "start_time": "2017-04-21T10:44:40.671248"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term, cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word, ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1 / (ratio+0.01)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:41.074113",
     "start_time": "2017-04-21T10:44:40.935216"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size= 74074\n"
     ]
    }
   ],
   "source": [
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "print('vocab_size=', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:41.180477",
     "start_time": "2017-04-21T10:44:41.075812"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(vocab)\n",
    "layer_0 = np.zeros((1,vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:41.314265",
     "start_time": "2017-04-21T10:44:41.183238"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:41.410003",
     "start_time": "2017-04-21T10:44:41.317005"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    global layer_0\n",
    "    \n",
    "    #clear out previous state, reste the layer\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(' '):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:41.520226",
     "start_time": "2017-04-21T10:44:41.411883"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_for_label(label):\n",
    "    if(label == 'positive'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:41.746358",
     "start_time": "2017-04-21T10:44:41.521983"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews, labels, hidden_nodes = 10, lr = 0.001):\n",
    "    \n",
    "        # set our random number generator\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab), hidden_nodes, 1, lr)\n",
    "        \n",
    "  \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(' '):\n",
    "                    review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)  \n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size  = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index  = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word]   = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "\n",
    "                \n",
    "    def init_network(self, input_nodes, hidden_nodes, outpu_nodes, lr):\n",
    "        self.input_nodes  = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.outpu_nodes  = outpu_nodes\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.W1 = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        self.W2 = np.random.normal(0.0, self.outpu_nodes**-0.5, \n",
    "                                  (self.hidden_nodes, self.outpu_nodes))\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.layer_0 = np.zeros((1, input_nodes))\n",
    "        \n",
    "        \n",
    "    def update_input_layer(self, review):\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "    \n",
    "    def get_target_for_label(self, label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def sigmoid(self, x, der = False):\n",
    "        if(der == True):\n",
    "            return x * (1 - x)\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "    \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            review = training_reviews[i]\n",
    "            label  = training_labels[i]\n",
    "            \n",
    "            # Forward pass\n",
    "            self.update_input_layer(review)\n",
    "            layer_1 = self.layer_0.dot(self.W1)\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.W2))\n",
    "            \n",
    "            # Backward pass\n",
    "            \n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            layer_2_delta = layer_2_error*self.sigmoid(layer_2, True)\n",
    "            \n",
    "            # Backpropagation error\n",
    "            layer_1_error = layer_2_delta.dot(self.W2.T)\n",
    "            # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "            layer_1_delta = layer_1_error\n",
    "            \n",
    "            # Update the weights\n",
    "            self.W2 -= layer_1.T.dot(layer_2_delta) * self.lr\n",
    "            self.W1 -= self.layer_0.T.dot(layer_1_delta) * self.lr\n",
    "            \n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "                \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if (i % 2500 ==  0):\n",
    "                print('')\n",
    "                \n",
    "                \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        correct = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.W1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.W2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\"     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:44:43.479788",
     "start_time": "2017-04-21T10:44:41.748181"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%debug\n",
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:50:29.217273",
     "start_time": "2017-04-21T10:44:43.481608"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):66.61 #Correct:1940 #Trained:2501 Training Accuracy:77.5%\n",
      "Progress:20.8% Speed(reviews/sec):69.34 #Correct:3987 #Trained:5001 Training Accuracy:79.7%\n",
      "Progress:31.2% Speed(reviews/sec):69.43 #Correct:6085 #Trained:7501 Training Accuracy:81.1%\n",
      "Progress:41.6% Speed(reviews/sec):69.49 #Correct:8204 #Trained:10001 Training Accuracy:82.0%\n",
      "Progress:52.0% Speed(reviews/sec):69.47 #Correct:10337 #Trained:12501 Training Accuracy:82.6%\n",
      "Progress:62.5% Speed(reviews/sec):69.51 #Correct:12423 #Trained:15001 Training Accuracy:82.8%\n",
      "Progress:72.9% Speed(reviews/sec):69.59 #Correct:14524 #Trained:17501 Training Accuracy:82.9%\n",
      "Progress:83.3% Speed(reviews/sec):69.47 #Correct:16697 #Trained:20001 Training Accuracy:83.4%\n",
      "Progress:93.7% Speed(reviews/sec):69.44 #Correct:18856 #Trained:22501 Training Accuracy:83.8%\n",
      "Progress:99.9% Speed(reviews/sec):69.41 #Correct:20172 #Trained:24000 Training Accuracy:84.0%"
     ]
    }
   ],
   "source": [
    "# %%debug\n",
    "\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T10:50:31.288052",
     "start_time": "2017-04-21T10:50:29.222059"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):485.1% #Correct:848 #Tested:1000 Testing Accuracy:84.8%"
     ]
    }
   ],
   "source": [
    "# %%debug\n",
    "\n",
    "# evaluate our model before training (just to show how horrible it is)\n",
    "\n",
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
